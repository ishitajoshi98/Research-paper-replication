{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96ae07736d2a495b9e557c81ab331912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e737de28c1ed4ab1b28a2189edc952dd",
              "IPY_MODEL_9a6d27b146fe47158a70a35f598c968d",
              "IPY_MODEL_42248898404c4e77a75fc428fcd6f8f7"
            ],
            "layout": "IPY_MODEL_01729e9b2fec46889ca6c3399a068867"
          }
        },
        "e737de28c1ed4ab1b28a2189edc952dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a549302e58ae4d749aba725f752eef7d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c552a1be25ba4a9694e39d78ee3027c2",
            "value": "README.md:‚Äá"
          }
        },
        "9a6d27b146fe47158a70a35f598c968d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_988b356191b84e4da3f2eb4cf8c2fb70",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd19ab9a95934174bf4f7998b3531df1",
            "value": 1
          }
        },
        "42248898404c4e77a75fc428fcd6f8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4f3424bdf840c48e333c5fa0fa78e7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8c1ddbabbf924d5a8f81e19e7829d0fd",
            "value": "‚Äá28.1k/?‚Äá[00:00&lt;00:00,‚Äá3.29MB/s]"
          }
        },
        "01729e9b2fec46889ca6c3399a068867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a549302e58ae4d749aba725f752eef7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c552a1be25ba4a9694e39d78ee3027c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "988b356191b84e4da3f2eb4cf8c2fb70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cd19ab9a95934174bf4f7998b3531df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c4f3424bdf840c48e333c5fa0fa78e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1ddbabbf924d5a8f81e19e7829d0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b886a078bfa8433496480dd4de7e95de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed3d3d0329b54228886a0320fc612890",
              "IPY_MODEL_ec669ad3504f4c2db71863a07ee56ffa",
              "IPY_MODEL_d3bfa4911b5b45be81b3846b9bec4bdd"
            ],
            "layout": "IPY_MODEL_94a635abde2e4ad9b13590fea2ed94b3"
          }
        },
        "ed3d3d0329b54228886a0320fc612890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803cb4c99894438791c52c9385ffe890",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_61fc56d5b1cd46509f4c587a716abe2f",
            "value": "de-en/train-00000-of-00001.parquet:‚Äá100%"
          }
        },
        "ec669ad3504f4c2db71863a07ee56ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3b5bdac696047d48a97137431848c9d",
            "max": 8797832,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc5c172cb13544e1926ee22bea397e5b",
            "value": 8797832
          }
        },
        "d3bfa4911b5b45be81b3846b9bec4bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e7bd792a9c4776a79514d55a9a50ee",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_34045bc86d1a47a692d2626b76fa0104",
            "value": "‚Äá8.80M/8.80M‚Äá[00:01&lt;00:00,‚Äá6.66MB/s]"
          }
        },
        "94a635abde2e4ad9b13590fea2ed94b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803cb4c99894438791c52c9385ffe890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61fc56d5b1cd46509f4c587a716abe2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3b5bdac696047d48a97137431848c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc5c172cb13544e1926ee22bea397e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70e7bd792a9c4776a79514d55a9a50ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34045bc86d1a47a692d2626b76fa0104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "106f1022e8a34dc892564459ad5bdca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac011bd07def40149c3a7962d78250d3",
              "IPY_MODEL_1eeb10a17e634a32aa18200edeb0d1aa",
              "IPY_MODEL_04f2cc74fdbe44208cc445c322d24519"
            ],
            "layout": "IPY_MODEL_5234e91701e04f0c89227340bb0c2f4b"
          }
        },
        "ac011bd07def40149c3a7962d78250d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b9666aae824830823d043f5b69a79f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_33aa022aad644910b2ec642bc367ded1",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "1eeb10a17e634a32aa18200edeb0d1aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d104f5a38cf94371b71b35dbd601b229",
            "max": 51467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18671c10c97d47d6ad9bdde595718d65",
            "value": 51467
          }
        },
        "04f2cc74fdbe44208cc445c322d24519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4b06d010f964418b51d0253622bfc41",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_16b00728734540799988cfb2f3c699aa",
            "value": "‚Äá51467/51467‚Äá[00:00&lt;00:00,‚Äá507662.49‚Äáexamples/s]"
          }
        },
        "5234e91701e04f0c89227340bb0c2f4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b9666aae824830823d043f5b69a79f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33aa022aad644910b2ec642bc367ded1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d104f5a38cf94371b71b35dbd601b229": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18671c10c97d47d6ad9bdde595718d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4b06d010f964418b51d0253622bfc41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16b00728734540799988cfb2f3c699aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Imports and setup"
      ],
      "metadata": {
        "id": "d2b4J6VUjcTm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbMHqCO1RVPG"
      },
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "xuEY89Pxj9OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Multi-Head Attention"
      ],
      "metadata": {
        "id": "Vx6Pur3WjjXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads # model is \"sliced\" into num_heads sections - each section learns something different\n",
        "\n",
        "        # Linear projections for Q, K, V\n",
        "        # nn.Linear(in_features, out_features) -> applies a matrix multiplication + bias to every input vector (XWT+b). So embedding vec * weight matrix for Q, K or V + bias\n",
        "        self.q_linear = nn.Linear(d_model, d_model) # We have d_model as in_features and out_features because we calculate query, key, value matrices\n",
        "        self.k_linear = nn.Linear(d_model, d_model) # first and then slice them into the desired dimensions. So each head receives a different Q, K, V matrix subset.\n",
        "        self.v_linear = nn.Linear(d_model, d_model) # Here we created 3 independent Linear layers.\n",
        "\n",
        "        # Output linear layer\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # üîπ Nested Scaled Dot-Product Attention block\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None, dropout=None):\n",
        "        \"\"\"\n",
        "        Q, K, V: (batch, heads, seq_len, d_k)\n",
        "        mask: (batch, 1, 1, seq_len_k) or None\n",
        "        \"\"\"\n",
        "        d_k = Q.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (d_k ** 0.5) # we scale by d_k the dot product gets large when d_k is large, making softmax outputs very peaky (too confident).\n",
        "                                                                     # Dividing by ‚àöd_k keeps the values in a reasonable range.\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "\n",
        "        if dropout is not None:\n",
        "            attn = dropout(attn)\n",
        "\n",
        "        output = torch.matmul(attn, V)\n",
        "        return output, attn\n",
        "\n",
        "    # üîπ Full Multi-Head Attention forward pass\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0) #batch size from the input embedding tensor X\n",
        "\n",
        "        # 1Ô∏è‚É£ Linear projections\n",
        "        Q = self.q_linear(query) # Dont get confused by the name in the parantheses. query, key and value are all the same matrix - i.e., the embedding matrix (X)\n",
        "        K = self.k_linear(key)   # and not the weight matrix for q,k,v. Weights and bias are initialized randomly at first for all.\n",
        "        V = self.v_linear(value) # Model will determine the \"correct\" weight and bias through its training. Once this training is complete, we get (batch size, seq_len, d_model) for each - Q, K, V\n",
        "\n",
        "        # 2Ô∏è‚É£ Split into heads\n",
        "        Q = Q.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) # -1 here tells Pytorch \"I don‚Äôt care what this dimension should be.\n",
        "        K = K.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) # Compute it so that the total number of elements stays the same\". -1 automatically becomes seq_len. We are going from 3d to 4d here.\n",
        "        V = V.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) # We first split each token‚Äôs embedding into head slices,then transpose so heads come first because when we do attention, we compute dot products per head.\n",
        "                                                                             # If we simply revrse the order like V.view(batch_size, self.num_heads, -1, self.d_k) then it would assume the wrong data order in memory.\n",
        "                                                                             # Whats happening in this code block: Q, K, V transformed matrices that we got from the previous step are being sliced into matrices with 64 cols each (512/8) with a batch size as determined by query.size(0) since we will be processing it in batches and can run in parallel\n",
        "\n",
        "        # 3Ô∏è‚É£ Apply scaled dot-product attention per head\n",
        "        x, attn = self.scaled_dot_product_attention(Q, K, V, mask, self.dropout)\n",
        "\n",
        "        # 4Ô∏è‚É£ Concatenate heads\n",
        "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k) # Transpose back to original shape (batch, seq_len, heads, d_k) and merge all heads ‚Üí (batch, seq_len, 512)\n",
        "        # when we do .transpose(), PyTorch does not physically rearrange elements in memory. It says \"Hey, when someone reads me, pretend my rows and columns are swapped ‚Äî but don‚Äôt actually copy or move anything yet\". view() requires the tensor‚Äôs elements to be laid out contiguously (in order) in memory. So we use contiguous() to copy our data into memory now, in the correct transposed order for view to work correctly\n",
        "\n",
        "        # 5Ô∏è‚É£ Final linear layer\n",
        "        output = self.out(x)  # this layer performs output= xWOT‚Äã+bO‚Äã where WO is a learnable weight. We need this because right now, the merged head features from the previous step are just sitting side by side. They don‚Äôt interact. This lets the model learn how to combine and weight the heads optimally.\n",
        "                              # It decides, for example: Maybe head 3‚Äôs info matters more than head 5‚Äôs or Maybe features from head 1 and head 7 should be mixed together.\n",
        "\n",
        "        return output, attn\n"
      ],
      "metadata": {
        "id": "B6eMpm8-jseq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EkyOqjxbjsNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Positional Encoding"
      ],
      "metadata": {
        "id": "mdseioCOjkvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The positional encoding matrix is computed once, stored forever, and reused for every sentence ‚Äî only the needed portion is added each time.\n",
        "# These sine‚Äìcosine patterns are fixed mathematical signals. They don‚Äôt depend on the data and don‚Äôt need to be learned\n",
        "# That‚Äôs why they‚Äôre stored as a buffer using: self.register_buffer('pe', pe) so they move with the model (to GPU/CPU) but aren‚Äôt updated by backpropagation.\n",
        "\n",
        "class PositionalEncoding(nn.Module): # we use a class instead of a function because we want PyTorch to treat positional encoding as a layer in the model not just some helper calculation\n",
        "                                     # Unlike a class, a fucntion runs once and forgets everything; Can‚Äôt save data (like the precomputed encoding); Isn‚Äôt part of the model (so you can‚Äôt save or load it easily).\n",
        "                                     # A function is like a cook ‚Äî you tell them the recipe every time. A class is like a kitchen machine ‚Äî you set it up once, and it‚Äôs ready to work whenever you need it.\n",
        "                                     # The nn.Module class in PyTorch is the base class for all neural network modules. It provides the fundamental structure and functionality for building and managing neural network architectures.\n",
        "\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__() # super() is a built-in Python function that lets a child class (PositionalEncoding) call methods from its parent class (nn.Module)\n",
        "                                                   # Why does super take PositionalEncoding as an argument? - \"Find the parent class of PositionalEncoding and call its methods in the context of self (this object)\"\"\n",
        "\n",
        "\n",
        "        # Create a matrix of shape (max_len, d_model)\n",
        "        # Each row is a position, each column is a dimension\n",
        "        pe = torch.zeros(max_len, d_model) # max_len = the largest number of tokens (words/subwords) that your model's positional encoding table will support. It is a global limit, not per sentence\n",
        "\n",
        "        # Create a column vector of positions [0, 1, 2, ..., max_len-1]\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # shape: (max_len, 1). Creates a column vector with 1 column and rows = max_len\n",
        "\n",
        "        # Compute the \"divisor term\" from the formula: 10000^(2i/d_model)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # formula is manipulated to make it easier to code. 2i is the even position\n",
        "\n",
        "        # Apply sin to even indices (0, 2, 4, ...)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "\n",
        "        # Apply cos to odd indices (1, 3, 5, ...)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Add a batch dimension (1, max_len, d_model)\n",
        "        pe = pe.unsqueeze(0) # Before this line, pe has shape [max_len, d_model]. After this line - [1, max_len, d_model].\n",
        "                             # when we add positional encodings to our input embeddings later, the input x will have shape [batch_size, seq_len, d_model].\n",
        "                             # To make the addition possible, both tensors must have compatible shapes.\n",
        "\n",
        "        # Register as a buffer so it‚Äôs not a learnable parameter but moves with the model (to GPU if needed)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x): # Use of this function? Every class that inherits from nn.Module must define how data flows through it ‚Äî that‚Äôs what the forward() method does. \"When I feed data into this layer, what should happen to it?\"\n",
        "        \"\"\"\n",
        "        x: (batch_size, seq_len, d_model)\n",
        "        \"\"\"\n",
        "        # Add the positional encoding up to the sequence length\n",
        "        x = x + self.pe[:, :x.size(1)] # self.pe[:, :x.size(1)] and self.pe[:, :x.size(1), :] do the same thing ‚Äî the last : is just optional because PyTorch automatically includes all remaining dimensions.\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "uRCaA_bFjtc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4tUtmMW-jtQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Positionwise Feed Forward layer"
      ],
      "metadata": {
        "id": "meQEhOOQXy7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1): # The constructor initializes the layer. d_model: input and output dimension (e.g. 512), d_ff: hidden layer dimension (e.g. 2048), dropout: dropout rate for regularization\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff) # First linear layer that expands each token‚Äôs embedding from size d_model ‚Üí d_ff.\n",
        "        self.linear2 = nn.Linear(d_ff, d_model) # Second linear layer that projects it back down from d_ff ‚Üí d_model.\n",
        "        self.dropout = nn.Dropout(dropout) # Randomly drops some activations during training to prevent overfitting.\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(F.relu(self.linear1(x)))) # inside to outside. apply the first linear layer (expand the dims), apply relu activation, apply dropout, project back to the og dim\n"
      ],
      "metadata": {
        "id": "-A1vWclpXygv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Encoder Layer"
      ],
      "metadata": {
        "id": "qc3JwQg9jmWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, num_heads, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(num_heads, d_model, dropout)\n",
        "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout) # in __init__ we just specify the dropout rate. Here we specify how to actually use this number. This creates an actual dropout layer\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # 1Ô∏è‚É£ Self-Attention sublayer (with residual connection + LayerNorm)\n",
        "        attn_output, _ = self.self_attn(x, x, x, mask) # When you call self.self_attn(...), PyTorch automatically runs that module‚Äôs own forward() method. So the arguments we see here are for forward and different than what we specified in  __init__\n",
        "        x = x + self.dropout(attn_output)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # 2Ô∏è‚É£ Feed-Forward sublayer (with residual connection + LayerNorm)\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = x + self.dropout(ff_output)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZsFWZHlajuKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Decoder Layer"
      ],
      "metadata": {
        "id": "32XqnbFUWXXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, num_heads, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(num_heads, d_model, dropout)\n",
        "        self.enc_dec_attn = MultiHeadAttention(num_heads, d_model, dropout) # creates the cross-attention sub-layer inside the decoder, which lets the decoder look at and extract relevant information from the encoder‚Äôs output.\n",
        "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
        "        # 1Ô∏è‚É£ Masked Self-Attention (decoder looks at past tokens only)\n",
        "        _x, _ = self.self_attn(x, x, x, tgt_mask) # ‚ÄúWhile predicting this word, which encoder words should I pay attention to?‚Äù\n",
        "        x = x + self.dropout(_x)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # 2Ô∏è‚É£ Encoder-Decoder Attention\n",
        "        _x, _ = self.enc_dec_attn(x, enc_output, enc_output, src_mask) # x = decoder's current hidden states (become queries Q), enc_output = encoder output (become keys K and values V), src_mask = mask for padding or attention limits\n",
        "        x = x + self.dropout(_x)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        # 3Ô∏è‚É£ Feed-Forward\n",
        "        _x = self.feed_forward(x)\n",
        "        x = x + self.dropout(_x)\n",
        "        x = self.norm3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "PujoOrQkWV5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Encoder Stack"
      ],
      "metadata": {
        "id": "kWG3YhUPWbI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_layers, num_heads, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(num_heads, d_model, d_ff, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "Gq20NzeZWaVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Decoder Stack"
      ],
      "metadata": {
        "id": "zMgAb67dWgg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_layers, num_heads, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(num_heads, d_model, d_ff, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_output, src_mask, tgt_mask)\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "7I3XOM1rWjuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Load Dataset"
      ],
      "metadata": {
        "id": "L_b7lpC_FGgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets sentencepiece\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load OPUS Books English‚ÄìGerman dataset\n",
        "dataset = load_dataset(\"opus_books\", \"de-en\")\n",
        "train = dataset[\"train\"]\n",
        "\n",
        "# Correct slicing method\n",
        "subset = train.select(range(min(50000, len(train))))\n",
        "\n",
        "src_texts = [ex[\"de\"] for ex in subset[\"translation\"]]\n",
        "tgt_texts = [ex[\"en\"] for ex in subset[\"translation\"]]\n",
        "\n",
        "print(\"Loaded\", len(src_texts), \"sentence pairs\")\n",
        "print(\"Example:\\n\", src_texts[0], \"‚Üí\", tgt_texts[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "96ae07736d2a495b9e557c81ab331912",
            "e737de28c1ed4ab1b28a2189edc952dd",
            "9a6d27b146fe47158a70a35f598c968d",
            "42248898404c4e77a75fc428fcd6f8f7",
            "01729e9b2fec46889ca6c3399a068867",
            "a549302e58ae4d749aba725f752eef7d",
            "c552a1be25ba4a9694e39d78ee3027c2",
            "988b356191b84e4da3f2eb4cf8c2fb70",
            "cd19ab9a95934174bf4f7998b3531df1",
            "2c4f3424bdf840c48e333c5fa0fa78e7",
            "8c1ddbabbf924d5a8f81e19e7829d0fd",
            "b886a078bfa8433496480dd4de7e95de",
            "ed3d3d0329b54228886a0320fc612890",
            "ec669ad3504f4c2db71863a07ee56ffa",
            "d3bfa4911b5b45be81b3846b9bec4bdd",
            "94a635abde2e4ad9b13590fea2ed94b3",
            "803cb4c99894438791c52c9385ffe890",
            "61fc56d5b1cd46509f4c587a716abe2f",
            "f3b5bdac696047d48a97137431848c9d",
            "dc5c172cb13544e1926ee22bea397e5b",
            "70e7bd792a9c4776a79514d55a9a50ee",
            "34045bc86d1a47a692d2626b76fa0104",
            "106f1022e8a34dc892564459ad5bdca7",
            "ac011bd07def40149c3a7962d78250d3",
            "1eeb10a17e634a32aa18200edeb0d1aa",
            "04f2cc74fdbe44208cc445c322d24519",
            "5234e91701e04f0c89227340bb0c2f4b",
            "03b9666aae824830823d043f5b69a79f",
            "33aa022aad644910b2ec642bc367ded1",
            "d104f5a38cf94371b71b35dbd601b229",
            "18671c10c97d47d6ad9bdde595718d65",
            "a4b06d010f964418b51d0253622bfc41",
            "16b00728734540799988cfb2f3c699aa"
          ]
        },
        "id": "t4zf_BpVIVd-",
        "outputId": "13960ed4-6176-40c6-f285-f3ad8f5225f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96ae07736d2a495b9e557c81ab331912"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "de-en/train-00000-of-00001.parquet:   0%|          | 0.00/8.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b886a078bfa8433496480dd4de7e95de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/51467 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "106f1022e8a34dc892564459ad5bdca7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 50000 sentence pairs\n",
            "Example:\n",
            " Source: http://www.zeno.org - Contumax GmbH & Co. KG ‚Üí Source: Project Gutenberg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine both languages into a single text file for shared BPE\n",
        "with open(\"train_combined.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for de, en in zip(src_texts, tgt_texts):\n",
        "        f.write(de.strip() + \"\\n\")\n",
        "        f.write(en.strip() + \"\\n\")\n",
        "\n",
        "print(\"Combined text file created with\", len(src_texts) * 2, \"lines\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FzepnVZMJd2",
        "outputId": "cd6491b8-78c3-4049-9414-1e7f2d16e91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined text file created with 100000 lines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train SentencePiece BPE Tokenizer (shared vocab)"
      ],
      "metadata": {
        "id": "TYVLzU42Hfi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "# Train SentencePiece tokenizer\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input=\"train_combined.txt\",\n",
        "    model_prefix=\"bpe\",\n",
        "    vocab_size=37000,         # same as paper\n",
        "    model_type=\"bpe\",         # Byte-Pair Encoding\n",
        "    character_coverage=1.0,   # cover all characters\n",
        "    pad_id=0, unk_id=1, bos_id=2, eos_id=3\n",
        ")\n",
        "\n",
        "print(\"‚úÖ SentencePiece tokenizer trained! Files generated: bpe.model, bpe.vocab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHhE04XLFFe-",
        "outputId": "50b0e519-9c91-42bd-c931-3431424a55ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ SentencePiece tokenizer trained! Files generated: bpe.model, bpe.vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Tokenizer & Test Encoding/Decoding"
      ],
      "metadata": {
        "id": "phqqxC6_QsMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp = spm.SentencePieceProcessor(model_file=\"bpe.model\")\n",
        "\n",
        "# Test on one pair\n",
        "src_example = src_texts[10]\n",
        "tgt_example = tgt_texts[10]\n",
        "\n",
        "src_ids = sp.encode(src_example, out_type=int)\n",
        "tgt_ids = sp.encode(tgt_example, out_type=int)\n",
        "\n",
        "print(\"German:\", src_example)\n",
        "print(\"‚Üí src_ids:\", src_ids[:20])\n",
        "print(\"English:\", tgt_example)\n",
        "print(\"‚Üí tgt_ids:\", tgt_ids[:20])\n",
        "\n",
        "# Decode back to verify\n",
        "print(\"Decoded back (src):\", sp.decode(src_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho4Iv1RAQrgR",
        "outputId": "8a9d8df4-7ede-4509-87c6-44e42c319bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German: ¬ªJane, ich liebe weder Spitzfindigkeiten noch Fragen; au√üerdem ist es gradezu widerlich, wenn ein Kind √§ltere Leute in dieser Weise zur Rede stellt.\n",
            "‚Üí src_ids: [94, 5110, 36864, 147, 2815, 3031, 9272, 17226, 3561, 307, 4557, 36888, 6878, 217, 179, 22058, 357, 28596, 36864, 428]\n",
            "English: \"Jane, I don't like cavillers or questioners; besides, there is something truly forbidding in a child taking up her elders in that manner.\n",
            "‚Üí tgt_ids: [150, 5110, 36864, 63, 944, 36877, 36851, 547, 9366, 178, 229, 363, 1954, 229, 36888, 4381, 36864, 399, 128, 1041]\n",
            "Decoded back (src): ¬ªJane, ich liebe weder Spitzfindigkeiten noch Fragen; au√üerdem ist es gradezu widerlich, wenn ein Kind √§ltere Leute in dieser Weise zur Rede stellt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Tokenized Tensors"
      ],
      "metadata": {
        "id": "JOK3RCzlQ4U0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def prepare_example(src_text, tgt_text, sp):\n",
        "    src_ids = sp.encode(src_text, out_type=int)\n",
        "    tgt_ids = sp.encode(tgt_text, out_type=int)\n",
        "\n",
        "    src = [2] + src_ids + [3]         # <sos> + src + <eos>\n",
        "    tgt_in = [2] + tgt_ids            # <sos> + tgt\n",
        "    tgt_out = tgt_ids + [3]           # tgt + <eos>\n",
        "\n",
        "    return torch.tensor(src), torch.tensor(tgt_in), torch.tensor(tgt_out)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_in_batch, tgt_out_batch = zip(*batch)\n",
        "    src_batch = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
        "    tgt_in_batch = pad_sequence(tgt_in_batch, padding_value=0, batch_first=True)\n",
        "    tgt_out_batch = pad_sequence(tgt_out_batch, padding_value=0, batch_first=True)\n",
        "    return src_batch, tgt_in_batch, tgt_out_batch\n"
      ],
      "metadata": {
        "id": "Kjph_zoDQ39W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Small Dataset Loader"
      ],
      "metadata": {
        "id": "eE__-FJWRM6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1) Pair up all sentences\n",
        "pairs = list(zip(src_texts, tgt_texts))\n",
        "\n",
        "# (NEW) Filter out very long sentences so training is easier\n",
        "def filter_by_length(pairs, sp, max_src_len=60, max_tgt_len=60):\n",
        "    filtered = []\n",
        "    for de, en in pairs:\n",
        "        de_ids = sp.encode(de, out_type=int)\n",
        "        en_ids = sp.encode(en, out_type=int)\n",
        "        if len(de_ids) <= max_src_len and len(en_ids) <= max_tgt_len:\n",
        "            filtered.append((de, en))\n",
        "    return filtered\n",
        "\n",
        "pairs = filter_by_length(pairs, sp, max_src_len=60, max_tgt_len=60)\n",
        "print(f\"After length filter: {len(pairs)} sentence pairs\")\n",
        "\n",
        "\n",
        "# 2) Simple 90/10 split into train / val\n",
        "split_idx = int(0.9 * len(pairs))\n",
        "train_pairs = pairs[:split_idx]\n",
        "val_pairs   = pairs[split_idx:]\n",
        "\n",
        "print(f\"Total pairs: {len(pairs)}, train: {len(train_pairs)}, val: {len(val_pairs)}\")\n",
        "\n",
        "# 3) (Optional) limit sizes for Colab\n",
        "train_pairs = train_pairs[:30000]\n",
        "val_pairs   = val_pairs[:3000]\n",
        "\n",
        "# 4) Tokenize using prepare_example()\n",
        "train_data = [prepare_example(src, tgt, sp) for src, tgt in train_pairs]\n",
        "val_data   = [prepare_example(src, tgt, sp) for src, tgt in val_pairs]\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True,  collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_data,   batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Quick sanity check\n",
        "for src, tgt_in, tgt_out in train_loader:\n",
        "    print(\"Batch shapes ‚Üí src:\", src.shape, \"tgt_in:\", tgt_in.shape, \"tgt_out:\", tgt_out.shape)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKa2fGXIQ0_W",
        "outputId": "4e6fd3cd-9805-415c-9fbd-828f4d707805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After length filter: 45393 sentence pairs\n",
            "Total pairs: 45393, train: 40853, val: 4540\n",
            "Batch shapes ‚Üí src: torch.Size([32, 59]) tgt_in: torch.Size([32, 57]) tgt_out: torch.Size([32, 57])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Wrapper"
      ],
      "metadata": {
        "id": "LQmOUv610UR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, num_layers, num_heads, d_model, d_ff, dropout=0.1, max_len=5000):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding layers\n",
        "        self.src_embed = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embed = nn.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        # Positional encodings\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len)\n",
        "        self.pos_decoder = PositionalEncoding(d_model, max_len)\n",
        "\n",
        "        # Encoder and decoder stacks\n",
        "        self.encoder = Encoder(num_layers, num_heads, d_model, d_ff, dropout)\n",
        "        self.decoder = Decoder(num_layers, num_heads, d_model, d_ff, dropout)\n",
        "\n",
        "        # Final linear output layer\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, src, tgt_in, src_mask=None, tgt_mask=None):\n",
        "        # 1Ô∏è‚É£ Embed source and target\n",
        "        src = self.src_embed(src) * math.sqrt(self.d_model)\n",
        "        tgt = self.tgt_embed(tgt_in) * math.sqrt(self.d_model)\n",
        "\n",
        "        # 2Ô∏è‚É£ Add positional encodings\n",
        "        src = self.pos_encoder(self.dropout(src))\n",
        "        tgt = self.pos_decoder(self.dropout(tgt))\n",
        "\n",
        "        # 3Ô∏è‚É£ Encoder-decoder pass\n",
        "        enc_output = self.encoder(src, src_mask)\n",
        "        dec_output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        # 4Ô∏è‚É£ Final linear layer\n",
        "        output = self.fc_out(dec_output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "6D5yKCmtFFHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention Mask"
      ],
      "metadata": {
        "id": "qVdZIdTf0sGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(seq, pad_token=0):\n",
        "    return (seq != pad_token).unsqueeze(1).unsqueeze(2)  # (batch, 1, 1, seq_len)\n",
        "\n",
        "def create_subsequent_mask(size):\n",
        "    # upper triangle (including diagonal) = True; we flip later\n",
        "    mask = torch.triu(torch.ones(size, size), diagonal=1).bool()\n",
        "    mask = ~mask  # now: lower triangle incl diag = True, future positions = False\n",
        "    # Shape: (1, 1, size, size) so it broadcasts nicely with padding mask\n",
        "    return mask.unsqueeze(0).unsqueeze(1)"
      ],
      "metadata": {
        "id": "12Hknwl30ucM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instantiate the Model"
      ],
      "metadata": {
        "id": "G-OcZpWw0yDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the Model\n",
        "\n",
        "# Get vocab size from tokenizer\n",
        "src_vocab_size = tgt_vocab_size = sp.get_piece_size()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = Transformer(\n",
        "    src_vocab_size=src_vocab_size,\n",
        "    tgt_vocab_size=tgt_vocab_size,\n",
        "    num_layers=3,     # a bit deeper\n",
        "    num_heads=4,      # fewer heads\n",
        "    d_model=256,      # smaller d_model -> much faster\n",
        "    d_ff=1024,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "print(\"Model initialized with vocab size:\", src_vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xog0f7H50zKv",
        "outputId": "b088b62e-273d-4d34-88b8-ecceb137183f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model initialized with vocab size: 37000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss & Optimizer"
      ],
      "metadata": {
        "id": "z2bv7YFt040K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Slight label smoothing helps MT a lot\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0, label_smoothing=0.1)\n",
        "\n",
        "# Adam with Transformer-style LR schedule\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=1.0,              # base LR, real LR comes from scheduler\n",
        "    betas=(0.9, 0.98),\n",
        "    eps=1e-9,\n",
        ")\n",
        "\n",
        "warmup_steps = 4000\n",
        "\n",
        "def lr_lambda(step):\n",
        "    # step starts from 1\n",
        "    step = max(step, 1)\n",
        "    return (model.d_model ** -0.5) * min(step ** -0.5, step * (warmup_steps ** -1.5))\n",
        "\n",
        "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ],
      "metadata": {
        "id": "oxfGQ_Yv05uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_val_loss(model, val_loader, criterion, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    n_batches = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt_in, tgt_out in val_loader:\n",
        "            src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "\n",
        "            src_mask = create_padding_mask(src)\n",
        "            tgt_mask = create_padding_mask(tgt_in) & create_subsequent_mask(tgt_in.size(1)).to(device)\n",
        "\n",
        "            output = model(src, tgt_in, src_mask, tgt_mask)\n",
        "\n",
        "            output_flat = output.view(-1, output.size(-1))\n",
        "            tgt_flat = tgt_out.view(-1)\n",
        "\n",
        "            loss = criterion(output_flat, tgt_flat)\n",
        "            total_loss += loss.item()\n",
        "            n_batches += 1\n",
        "\n",
        "    return total_loss / max(1, n_batches)"
      ],
      "metadata": {
        "id": "01mV5_wDDDvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, src_sentence, sp, max_len=50, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Prepare source\n",
        "        src_ids = [2] + sp.encode(src_sentence, out_type=int) + [3]  # <sos> ... <eos>\n",
        "        src = torch.tensor(src_ids, dtype=torch.long, device=device).unsqueeze(0)  # (1, src_len)\n",
        "        src_mask = create_padding_mask(src)\n",
        "\n",
        "        # Encode EXACTLY like in model.forward\n",
        "        src_emb = model.src_embed(src) * math.sqrt(model.d_model)\n",
        "        src_emb = model.pos_encoder(model.dropout(src_emb))\n",
        "        enc_output = model.encoder(src_emb, src_mask)\n",
        "\n",
        "        # Start target with <sos>\n",
        "        tgt = torch.tensor([[2]], dtype=torch.long, device=device)\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            tgt_mask = create_padding_mask(tgt) & create_subsequent_mask(tgt.size(1)).to(device)\n",
        "\n",
        "            tgt_emb = model.tgt_embed(tgt) * math.sqrt(model.d_model)\n",
        "            tgt_emb = model.pos_decoder(model.dropout(tgt_emb))\n",
        "\n",
        "            dec_output = model.decoder(tgt_emb, enc_output, src_mask, tgt_mask)\n",
        "            logits = model.fc_out(dec_output[:, -1])  # (1, vocab_size)\n",
        "            next_token = logits.argmax(-1).item()\n",
        "\n",
        "            tgt = torch.cat(\n",
        "                [tgt, torch.tensor([[next_token]], dtype=torch.long, device=device)],\n",
        "                dim=1,\n",
        "            )\n",
        "\n",
        "            if next_token == 3:  # <eos>\n",
        "                break\n",
        "\n",
        "        # remove <sos> and possible final <eos>\n",
        "        out_tokens = tgt.squeeze(0).tolist()[1:]\n",
        "        if out_tokens and out_tokens[-1] == 3:\n",
        "            out_tokens = out_tokens[:-1]\n",
        "        return sp.decode(out_tokens)\n"
      ],
      "metadata": {
        "id": "OdC2deyfDXQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sacrebleu\n",
        "import sacrebleu\n",
        "\n",
        "def evaluate_bleu(model, val_pairs, sp, device=\"cpu\", num_examples=50, max_len=50):\n",
        "    model.eval()\n",
        "    hyps = []\n",
        "    refs = []\n",
        "\n",
        "    num_examples = min(num_examples, len(val_pairs))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_examples):\n",
        "            src_text, tgt_text = val_pairs[i]\n",
        "            hyp = greedy_decode(model, src_text, sp, max_len=max_len, device=device)\n",
        "\n",
        "            hyps.append(hyp)\n",
        "            refs.append(tgt_text)\n",
        "\n",
        "    bleu = sacrebleu.corpus_bleu(hyps, [refs])\n",
        "    return bleu.score\n"
      ],
      "metadata": {
        "id": "xDrmHTrwDaav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34753d2c-f7dc-44a4-9d53-acffdd87e83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/104.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sample_translations(model, val_pairs, sp, device=\"cpu\", num_examples=5, max_len=50):\n",
        "    model.eval()\n",
        "    print(\"\\nSample translations:\")\n",
        "    print(\"-\" * 80)\n",
        "    with torch.no_grad():\n",
        "        for i in range(min(num_examples, len(val_pairs))):\n",
        "            src_text, tgt_text = val_pairs[i]\n",
        "            pred = greedy_decode(model, src_text, sp, max_len=max_len, device=device)\n",
        "            print(f\"[SRC] {src_text}\")\n",
        "            print(f\"[PRED] {pred}\")\n",
        "            print(f\"[TGT] {tgt_text}\")\n",
        "            print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "FfuL5OBeEAwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "n_epochs = 20  # more epochs now that model is smaller\n",
        "# device is already defined above when we created the model\n",
        "\n",
        "global_step = 0\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    # ---- Train ----\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "\n",
        "    loop = tqdm(train_loader, leave=True)\n",
        "    for src, tgt_in, tgt_out in loop:\n",
        "        src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device)\n",
        "\n",
        "        src_mask = create_padding_mask(src)\n",
        "        tgt_mask = create_padding_mask(tgt_in) & create_subsequent_mask(tgt_in.size(1)).to(device)\n",
        "\n",
        "        output = model(src, tgt_in, src_mask, tgt_mask)\n",
        "\n",
        "        output_flat = output.view(-1, output.size(-1))\n",
        "        tgt_flat = tgt_out.view(-1)\n",
        "\n",
        "        loss = criterion(output_flat, tgt_flat)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # (NEW) gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        global_step += 1\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        loop.set_description(f\"Epoch {epoch}\")\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    # ---- Validation loss ----\n",
        "    val_loss = evaluate_val_loss(model, val_loader, criterion, device=device)\n",
        "\n",
        "    # ---- BLEU on a subset of validation pairs ----\n",
        "    bleu = evaluate_bleu(model, val_pairs, sp, device=device, num_examples=50, max_len=50)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch} summary:\")\n",
        "    print(f\"  Train loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"  Val loss:   {val_loss:.4f}\")\n",
        "    print(f\"  BLEU (50 val examples): {bleu:.2f}\")\n",
        "\n",
        "    # Show a few sample translations from the validation set\n",
        "    show_sample_translations(model, val_pairs, sp, device=device, num_examples=3, max_len=50)\n"
      ],
      "metadata": {
        "id": "iQauUJWqf8HL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2885b27c-366a-4973-d770-a976dcafcc0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:47<00:00, 19.64it/s, loss=6.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 summary:\n",
            "  Train loss: 7.4071\n",
            "  Val loss:   6.2583\n",
            "  BLEU (50 val examples): 0.51\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"I's a few.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He was a little, and the other, and the other.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] \"I's a little, he had been to be a little, he had been to be a little, he had been to be a little, and he had been to the other.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 19.98it/s, loss=5.84]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 summary:\n",
            "  Train loss: 5.9766\n",
            "  Val loss:   5.9151\n",
            "  BLEU (50 val examples): 0.86\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is a little girl.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He said to the young girl, and said, and said, and had been a little girl.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] \"You have a little girl, he said, he had been a little girl, he had been very long time to her in a little girl, and he had been a little girl, \"I'll be a little child, he'll\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 20.00it/s, loss=5.74]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 summary:\n",
            "  Train loss: 5.6574\n",
            "  Val loss:   5.7688\n",
            "  BLEU (50 val examples): 0.98\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he was a few minutes.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He was a voice, and the voice of the voice, and the voice of the voice of the voice.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] \"Oh, he would have been a voice, and he would have been a voice to be a voice, or two minutes, or two minutes, or two minutes, or two minutes, and he had been to be a voice.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 20.00it/s, loss=5.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 summary:\n",
            "  Train loss: 5.4377\n",
            "  Val loss:   5.6773\n",
            "  BLEU (50 val examples): 3.61\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he was gone.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He looked at the voice, and looked at the voice.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, I have no longer a little thing, and he must be afraid of course, he must be afraid of course, and he must be afraid of course, for a voice, and he had no longer a voice, that he had no\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 20.03it/s, loss=5.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 summary:\n",
            "  Train loss: 5.2724\n",
            "  Val loss:   5.5929\n",
            "  BLEU (50 val examples): 3.33\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is dead.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He was heard a smile, and his voice, and his voice.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, please, he was still a moment,' said Oblonsky, 'and he spoke to be a little one another, and he spoke to be a moment, and he said, and he spoke to his voice.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 20.03it/s, loss=5.42]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6 summary:\n",
            "  Train loss: 5.0827\n",
            "  Val loss:   5.5121\n",
            "  BLEU (50 val examples): 4.07\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is married.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He's a good-bye, and he's a good-bye,' said Oblonsky.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Ah, you must be a good-bye, and he said to himself, 'Oh, you must be a good-bye, you,' said to the key, 'and he was in the key, you must be a moment later,\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 19.98it/s, loss=4.81]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7 summary:\n",
            "  Train loss: 4.9260\n",
            "  Val loss:   5.4842\n",
            "  BLEU (50 val examples): 6.53\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is dead, he is dead.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He looked at the Countess Lydia Ivanovna and looked at the Countess Nordston.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, I must be a good fellow,' said Oblonsky, in a voice, and he was still in a voice.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 19.97it/s, loss=4.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 summary:\n",
            "  Train loss: 4.7971\n",
            "  Val loss:   5.4626\n",
            "  BLEU (50 val examples): 4.31\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he was silent.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He looked at the Countess,' said Oblonsky, looking at the Countess Nordston.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, he must be a good deal of course,' said Oblonsky, 'he must be a good-bye, or two, or two, or two, he must be a good-bye, or something!'\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:47<00:00, 19.81it/s, loss=5.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9 summary:\n",
            "  Train loss: 4.6889\n",
            "  Val loss:   5.4632\n",
            "  BLEU (50 val examples): 5.11\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he was going to Paris.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He's heard the Countess Nordston,' said Oblonsky, looking at the Countess Nordston.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, please don't want anything,' said Oblonsky, 'and he must be a key in the lock, or something else, or something else, or something else, or something else must be a key.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:47<00:00, 19.94it/s, loss=4.52]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 summary:\n",
            "  Train loss: 4.5933\n",
            "  Val loss:   5.4669\n",
            "  BLEU (50 val examples): 5.79\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is mad.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He looked at the Countess,' said Oblonsky.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, I must be a key,' said Oblonsky, in a low voice, and he was not a key to her.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 19.96it/s, loss=4.76]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11 summary:\n",
            "  Train loss: 4.5130\n",
            "  Val loss:   5.4658\n",
            "  BLEU (50 val examples): 5.12\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is very pretty, he.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He has heard a Countess,' said Oblonsky, looking at the Countess, and looked at the Countess.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, I must be glad he should not be glad to be glad to be,' said Oblonsky, in a voice, in a low voice, 'to-house, and he was afraid of course, and he was afraid of course, and\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 19.97it/s, loss=4.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12 summary:\n",
            "  Train loss: 4.4377\n",
            "  Val loss:   5.4706\n",
            "  BLEU (50 val examples): 6.71\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is sure.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He looked at Oblonsky, and was looking at him.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, I must be a moment,' said Oblonsky, in a few minutes, in a few minutes, in a few minutes, and he said in a low voice, 'I must be a moment when he was to be a ball.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 20.00it/s, loss=4.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13 summary:\n",
            "  Train loss: 4.3690\n",
            "  Val loss:   5.4864\n",
            "  BLEU (50 val examples): 6.18\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is mad.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He looked at the Countess Lydia Ivanovna and spoke to him.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, it is not possible to be a bit of the lock, or something!' said Oblonsky, in a low tone, and he spoke to her.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 20.00it/s, loss=4.79]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14 summary:\n",
            "  Train loss: 4.3084\n",
            "  Val loss:   5.4931\n",
            "  BLEU (50 val examples): 6.36\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is sure, he is.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He looked at the Countess and was looking at it.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, I should be glad to see him,' said Oblonsky, in a low tone, and he was thinking of her.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 20.00it/s, loss=4.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15 summary:\n",
            "  Train loss: 4.2526\n",
            "  Val loss:   5.4997\n",
            "  BLEU (50 val examples): 5.64\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is in Paris.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] 'I know,' said Oblonsky, and looked at the Countess Nordston.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, I must be a little bit of the house,' said Oblonsky, in a low voice, and in a low tone of her.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:46<00:00, 20.00it/s, loss=4.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16 summary:\n",
            "  Train loss: 4.1986\n",
            "  Val loss:   5.5135\n",
            "  BLEU (50 val examples): 6.07\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is gone.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He has heard the Countess,' said the Countess, and looked at the Countess.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, I must be a little more than a key to her, or two,' said Oblonsky. 'Oh, I must be a key in this way, and I have to be a key to her.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:47<00:00, 19.94it/s, loss=4.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17 summary:\n",
            "  Train loss: 4.1517\n",
            "  Val loss:   5.5338\n",
            "  BLEU (50 val examples): 6.30\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is alive.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He was looking at the Countess Lydia Ivanovna and his voice was looking at the Countess.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, I have a key to her,' he said in a low voice; 'he must be a key or two.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:47<00:00, 19.88it/s, loss=4.16]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18 summary:\n",
            "  Train loss: 4.1092\n",
            "  Val loss:   5.5356\n",
            "  BLEU (50 val examples): 6.79\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, Paris,\" he went on.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He has heard one of the Countess Lydia Ivanovna and heard Oblonsky's voice.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, I should think,' said Oblonsky, in a firm tone, 'he must be a key or two times when he should be in the key and he should be glad to be glad to see.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:47<00:00, 19.94it/s, loss=4.09]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19 summary:\n",
            "  Train loss: 4.0662\n",
            "  Val loss:   5.5518\n",
            "  BLEU (50 val examples): 6.42\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, he is alive.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He was looking at the Countess Lydia Ivanovna and of the Countess,' said Oblonsky, a voice.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, please do not come to her,' said Oblonsky, in a firm voice, and he spoke to her.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938/938 [00:47<00:00, 19.65it/s, loss=4.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20 summary:\n",
            "  Train loss: 4.0267\n",
            "  Val loss:   5.5706\n",
            "  BLEU (50 val examples): 6.29\n",
            "\n",
            "Sample translations:\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªJa, er f√§hrt nach Paris.\n",
            "[PRED] \"Yes, Paris,\" he said, \"he's.\n",
            "[TGT] 'Yes, he is going to Paris.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] Er hat gestern eine Stimme geh√∂rt¬´, sagte die Gr√§fin Lydia Iwanowna und blickte dabei Stepan Arkadjewitsch an.\n",
            "[PRED] He has heard the Countess,' said Oblonsky, looking at the Countess.\n",
            "[TGT] He heard a voice yesterday,' said the Countess, with a look at Oblonsky.\n",
            "--------------------------------------------------------------------------------\n",
            "[SRC] ¬ªAch, eine Stimme!¬´ sprach Oblonski ihr nach; er sagte sich, da√ü er in dieser Gesellschaft m√∂glichst vorsichtig sein m√ºsse, wo etwas vorgehe oder vorgehen solle, wozu er noch keinen Schl√ºssel habe.\n",
            "[PRED] 'Oh, please do!' said Oblonsky in a voice, in a low voice, or something like a key.\n",
            "[TGT] 'Ah, a voice!' Oblonsky remarked, feeling that he must be as careful as possible in this company, where something peculiar occurred, or was supposed to occur, to which he as yet lacked a clue.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model"
      ],
      "metadata": {
        "id": "LXNWur8I3q5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "save_path = \"/content/drive/MyDrive/transformer_en_de.pt\"\n",
        "\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model saved to: {save_path}\")"
      ],
      "metadata": {
        "id": "jnU6VMdHjuqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d9e91a-7801-40c3-92f9-56c875ec9ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Model saved to: /content/drive/MyDrive/transformer_en_de.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation = greedy_decode(model, \"Ich liebe Katzen\", sp, device=device)\n",
        "print(\"Translated:\", translation)"
      ],
      "metadata": {
        "id": "K-i-Zj2F4JpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8f572c-b714-42f6-9479-04c389bde6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated: I like cats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p-5Z13nQAWhI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}