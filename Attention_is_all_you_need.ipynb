{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dacfc109e355408481c51a36a75e952b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b04ed7312dfd445e9fc14098114c5c79",
              "IPY_MODEL_28415cc4f6e54f0c89f2bb894fc1b422",
              "IPY_MODEL_cbbabf858e734c82bbf777fe3e56c40a"
            ],
            "layout": "IPY_MODEL_88abf30ba4ce4c5a855f3aac77bdebb7"
          }
        },
        "b04ed7312dfd445e9fc14098114c5c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13427b0d93cd41d3834eca65db011cb7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9c4419463dc2466691213803a995bceb",
            "value": "README.md:‚Äá"
          }
        },
        "28415cc4f6e54f0c89f2bb894fc1b422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb07953282784d80a27469980f8abc26",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ecdda746d604f958806b62479da56f3",
            "value": 1
          }
        },
        "cbbabf858e734c82bbf777fe3e56c40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ed934e2d9ff4239866004fa69c7d06d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f7ee89b5e532493796da15902069d182",
            "value": "‚Äá28.1k/?‚Äá[00:00&lt;00:00,‚Äá1.57MB/s]"
          }
        },
        "88abf30ba4ce4c5a855f3aac77bdebb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13427b0d93cd41d3834eca65db011cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c4419463dc2466691213803a995bceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb07953282784d80a27469980f8abc26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5ecdda746d604f958806b62479da56f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ed934e2d9ff4239866004fa69c7d06d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7ee89b5e532493796da15902069d182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4786cc09aae4ef0ac39daae839f6300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_541bc243d51546d09c98b5ca85b3ca2e",
              "IPY_MODEL_49c6d72faf774894afa9c6964918a32f",
              "IPY_MODEL_8756f5361aae4d82916202ce985cceb9"
            ],
            "layout": "IPY_MODEL_0178952a51574150bdda12d3b386d83f"
          }
        },
        "541bc243d51546d09c98b5ca85b3ca2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ff978a944484d229de2a7dce6240a24",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ad07b3f53c3e4f1d869f2ccebed05983",
            "value": "de-en/train-00000-of-00001.parquet:‚Äá100%"
          }
        },
        "49c6d72faf774894afa9c6964918a32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f45193be8a9547a68404097487c7987b",
            "max": 8797832,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4af71930e2964a6a8d714b8f85487e32",
            "value": 8797832
          }
        },
        "8756f5361aae4d82916202ce985cceb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ecb84353d5d4d888e6bae91e05c93bb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d18faf3a9bb74347861ab9d1b4bc4446",
            "value": "‚Äá8.80M/8.80M‚Äá[00:01&lt;00:00,‚Äá5.49MB/s]"
          }
        },
        "0178952a51574150bdda12d3b386d83f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ff978a944484d229de2a7dce6240a24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad07b3f53c3e4f1d869f2ccebed05983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f45193be8a9547a68404097487c7987b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4af71930e2964a6a8d714b8f85487e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ecb84353d5d4d888e6bae91e05c93bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d18faf3a9bb74347861ab9d1b4bc4446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "587ad9e552954fcfa7815fcd4e92fba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dc6ff4174d042339327cdadcb0957ab",
              "IPY_MODEL_bc72fbff44b74c8cb40ca1a82b9adbcc",
              "IPY_MODEL_3cf13e06f2cc4a67ab9155bd1a979d69"
            ],
            "layout": "IPY_MODEL_abddb72904f845568d1774f8e7c8c1d3"
          }
        },
        "2dc6ff4174d042339327cdadcb0957ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_096525b9ef9849b7b78d3b5c9f750b91",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2d1b16c989e44807aaf75a14a750ba9c",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "bc72fbff44b74c8cb40ca1a82b9adbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_398d89c3aa094ff3940d55c948c59dbf",
            "max": 51467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f83b3d49d014d57bb56e4b28df905fe",
            "value": 51467
          }
        },
        "3cf13e06f2cc4a67ab9155bd1a979d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a9cfa32cc2b471098dc2e760a57e5f3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_879c37cd34194da782e41284cedd8872",
            "value": "‚Äá51467/51467‚Äá[00:00&lt;00:00,‚Äá190263.77‚Äáexamples/s]"
          }
        },
        "abddb72904f845568d1774f8e7c8c1d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "096525b9ef9849b7b78d3b5c9f750b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1b16c989e44807aaf75a14a750ba9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "398d89c3aa094ff3940d55c948c59dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f83b3d49d014d57bb56e4b28df905fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a9cfa32cc2b471098dc2e760a57e5f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879c37cd34194da782e41284cedd8872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Imports and setup"
      ],
      "metadata": {
        "id": "d2b4J6VUjcTm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbMHqCO1RVPG"
      },
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "xuEY89Pxj9OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Multi-Head Attention"
      ],
      "metadata": {
        "id": "Vx6Pur3WjjXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads # model is \"sliced\" into num_heads sections - each section learns something different\n",
        "\n",
        "        # Linear projections for Q, K, V\n",
        "        # nn.Linear(in_features, out_features) -> applies a matrix multiplication + bias to every input vector (XWT+b). So embedding vec * weight matrix for Q, K or V + bias\n",
        "        self.q_linear = nn.Linear(d_model, d_model) # We have d_model as in_features and out_features because we calculate query, key, value matrices\n",
        "        self.k_linear = nn.Linear(d_model, d_model) # first and then slice them into the desired dimensions. So each head receives a different Q, K, V matrix subset.\n",
        "        self.v_linear = nn.Linear(d_model, d_model) # Here we created 3 independent Linear layers.\n",
        "\n",
        "        # Output linear layer\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # üîπ Nested Scaled Dot-Product Attention block\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None, dropout=None):\n",
        "        \"\"\"\n",
        "        Q, K, V: (batch, heads, seq_len, d_k)\n",
        "        mask: (batch, 1, 1, seq_len_k) or None\n",
        "        \"\"\"\n",
        "        d_k = Q.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (d_k ** 0.5) # we scale by d_k the dot product gets large when d_k is large, making softmax outputs very peaky (too confident).\n",
        "                                                                     # Dividing by ‚àöd_k keeps the values in a reasonable range.\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "\n",
        "        if dropout is not None:\n",
        "            attn = dropout(attn)\n",
        "\n",
        "        output = torch.matmul(attn, V)\n",
        "        return output, attn\n",
        "\n",
        "    # üîπ Full Multi-Head Attention forward pass\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0) #batch size from the input embedding tensor X\n",
        "\n",
        "        # 1Ô∏è‚É£ Linear projections\n",
        "        Q = self.q_linear(query) # Dont get confused by the name in the parantheses. query, key and value are all the same matrix - i.e., the embedding matrix (X)\n",
        "        K = self.k_linear(key)   # and not the weight matrix for q,k,v. Weights and bias are initialized randomly at first for all.\n",
        "        V = self.v_linear(value) # Model will determine the \"correct\" weight and bias through its training. Once this training is complete, we get (batch size, seq_len, d_model) for each - Q, K, V\n",
        "\n",
        "        # 2Ô∏è‚É£ Split into heads\n",
        "        Q = Q.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) # -1 here tells Pytorch \"I don‚Äôt care what this dimension should be.\n",
        "        K = K.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) # Compute it so that the total number of elements stays the same\". -1 automatically becomes seq_len. We are going from 3d to 4d here.\n",
        "        V = V.view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) # We first split each token‚Äôs embedding into head slices,then transpose so heads come first because when we do attention, we compute dot products per head.\n",
        "                                                                             # If we simply revrse the order like V.view(batch_size, self.num_heads, -1, self.d_k) then it would assume the wrong data order in memory.\n",
        "                                                                             # Whats happening in this code block: Q, K, V transformed matrices that we got from the previous step are being sliced into matrices with 64 cols each (512/8) with a batch size as determined by query.size(0) since we will be processing it in batches and can run in parallel\n",
        "\n",
        "        # 3Ô∏è‚É£ Apply scaled dot-product attention per head\n",
        "        x, attn = self.scaled_dot_product_attention(Q, K, V, mask, self.dropout)\n",
        "\n",
        "        # 4Ô∏è‚É£ Concatenate heads\n",
        "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k) # Transpose back to original shape (batch, seq_len, heads, d_k) and merge all heads ‚Üí (batch, seq_len, 512)\n",
        "        # when we do .transpose(), PyTorch does not physically rearrange elements in memory. It says \"Hey, when someone reads me, pretend my rows and columns are swapped ‚Äî but don‚Äôt actually copy or move anything yet\". view() requires the tensor‚Äôs elements to be laid out contiguously (in order) in memory. So we use contiguous() to copy our data into memory now, in the correct transposed order for view to work correctly\n",
        "\n",
        "        # 5Ô∏è‚É£ Final linear layer\n",
        "        output = self.out(x)  # this layer performs output= xWOT‚Äã+bO‚Äã where WO is a learnable weight. We need this because right now, the merged head features from the previous step are just sitting side by side. They don‚Äôt interact. This lets the model learn how to combine and weight the heads optimally.\n",
        "                              # It decides, for example: Maybe head 3‚Äôs info matters more than head 5‚Äôs or Maybe features from head 1 and head 7 should be mixed together.\n",
        "\n",
        "        return output, attn\n"
      ],
      "metadata": {
        "id": "B6eMpm8-jseq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EkyOqjxbjsNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Positional Encoding"
      ],
      "metadata": {
        "id": "mdseioCOjkvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The positional encoding matrix is computed once, stored forever, and reused for every sentence ‚Äî only the needed portion is added each time.\n",
        "# These sine‚Äìcosine patterns are fixed mathematical signals. They don‚Äôt depend on the data and don‚Äôt need to be learned\n",
        "# That‚Äôs why they‚Äôre stored as a buffer using: self.register_buffer('pe', pe) so they move with the model (to GPU/CPU) but aren‚Äôt updated by backpropagation.\n",
        "\n",
        "class PositionalEncoding(nn.Module): # we use a class instead of a function because we want PyTorch to treat positional encoding as a layer in the model not just some helper calculation\n",
        "                                     # Unlike a class, a fucntion runs once and forgets everything; Can‚Äôt save data (like the precomputed encoding); Isn‚Äôt part of the model (so you can‚Äôt save or load it easily).\n",
        "                                     # A function is like a cook ‚Äî you tell them the recipe every time. A class is like a kitchen machine ‚Äî you set it up once, and it‚Äôs ready to work whenever you need it.\n",
        "                                     # The nn.Module class in PyTorch is the base class for all neural network modules. It provides the fundamental structure and functionality for building and managing neural network architectures.\n",
        "\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__() # super() is a built-in Python function that lets a child class (PositionalEncoding) call methods from its parent class (nn.Module)\n",
        "                                                   # Why does super take PositionalEncoding as an argument? - \"Find the parent class of PositionalEncoding and call its methods in the context of self (this object)\"\"\n",
        "\n",
        "\n",
        "        # Create a matrix of shape (max_len, d_model)\n",
        "        # Each row is a position, each column is a dimension\n",
        "        pe = torch.zeros(max_len, d_model) # max_len = the largest number of tokens (words/subwords) that your model's positional encoding table will support. It is a global limit, not per sentence\n",
        "\n",
        "        # Create a column vector of positions [0, 1, 2, ..., max_len-1]\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # shape: (max_len, 1). Creates a column vector with 1 column and rows = max_len\n",
        "\n",
        "        # Compute the \"divisor term\" from the formula: 10000^(2i/d_model)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # formula is manipulated to make it easier to code. 2i is the even position\n",
        "\n",
        "        # Apply sin to even indices (0, 2, 4, ...)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "\n",
        "        # Apply cos to odd indices (1, 3, 5, ...)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Add a batch dimension (1, max_len, d_model)\n",
        "        pe = pe.unsqueeze(0) # Before this line, pe has shape [max_len, d_model]. After this line - [1, max_len, d_model].\n",
        "                             # when we add positional encodings to our input embeddings later, the input x will have shape [batch_size, seq_len, d_model].\n",
        "                             # To make the addition possible, both tensors must have compatible shapes.\n",
        "\n",
        "        # Register as a buffer so it‚Äôs not a learnable parameter but moves with the model (to GPU if needed)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x): # Use of this function? Every class that inherits from nn.Module must define how data flows through it ‚Äî that‚Äôs what the forward() method does. \"When I feed data into this layer, what should happen to it?\"\n",
        "        \"\"\"\n",
        "        x: (batch_size, seq_len, d_model)\n",
        "        \"\"\"\n",
        "        # Add the positional encoding up to the sequence length\n",
        "        x = x + self.pe[:, :x.size(1)] # self.pe[:, :x.size(1)] and self.pe[:, :x.size(1), :] do the same thing ‚Äî the last : is just optional because PyTorch automatically includes all remaining dimensions.\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "uRCaA_bFjtc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4tUtmMW-jtQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Positionwise Feed Forward layer"
      ],
      "metadata": {
        "id": "meQEhOOQXy7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1): # The constructor initializes the layer. d_model: input and output dimension (e.g. 512), d_ff: hidden layer dimension (e.g. 2048), dropout: dropout rate for regularization\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff) # First linear layer that expands each token‚Äôs embedding from size d_model ‚Üí d_ff.\n",
        "        self.linear2 = nn.Linear(d_ff, d_model) # Second linear layer that projects it back down from d_ff ‚Üí d_model.\n",
        "        self.dropout = nn.Dropout(dropout) # Randomly drops some activations during training to prevent overfitting.\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.dropout(F.relu(self.linear1(x)))) # inside to outside. apply the first linear layer (expand the dims), apply relu activation, apply dropout, project back to the og dim\n"
      ],
      "metadata": {
        "id": "-A1vWclpXygv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Encoder Layer"
      ],
      "metadata": {
        "id": "qc3JwQg9jmWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, num_heads, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(num_heads, d_model, dropout)\n",
        "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout) # in __init__ we just specify the dropout rate. Here we specify how to actually use this number. This creates an actual dropout layer\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # 1Ô∏è‚É£ Self-Attention sublayer (with residual connection + LayerNorm)\n",
        "        attn_output, _ = self.self_attn(x, x, x, mask) # When you call self.self_attn(...), PyTorch automatically runs that module‚Äôs own forward() method. So the arguments we see here are for forward and different than what we specified in  __init__\n",
        "        x = x + self.dropout(attn_output)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # 2Ô∏è‚É£ Feed-Forward sublayer (with residual connection + LayerNorm)\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = x + self.dropout(ff_output)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZsFWZHlajuKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Decoder Layer"
      ],
      "metadata": {
        "id": "32XqnbFUWXXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, num_heads, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(num_heads, d_model, dropout)\n",
        "        self.enc_dec_attn = MultiHeadAttention(num_heads, d_model, dropout) # creates the cross-attention sub-layer inside the decoder, which lets the decoder look at and extract relevant information from the encoder‚Äôs output.\n",
        "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
        "        # 1Ô∏è‚É£ Masked Self-Attention (decoder looks at past tokens only)\n",
        "        _x, _ = self.self_attn(x, x, x, tgt_mask) # ‚ÄúWhile predicting this word, which encoder words should I pay attention to?‚Äù\n",
        "        x = x + self.dropout(_x)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # 2Ô∏è‚É£ Encoder-Decoder Attention\n",
        "        _x, _ = self.enc_dec_attn(x, enc_output, enc_output, src_mask) # x = decoder's current hidden states (become queries Q), enc_output = encoder output (become keys K and values V), src_mask = mask for padding or attention limits\n",
        "        x = x + self.dropout(_x)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        # 3Ô∏è‚É£ Feed-Forward\n",
        "        _x = self.feed_forward(x)\n",
        "        x = x + self.dropout(_x)\n",
        "        x = self.norm3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "PujoOrQkWV5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Encoder Stack"
      ],
      "metadata": {
        "id": "kWG3YhUPWbI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_layers, num_heads, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(num_heads, d_model, d_ff, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "Gq20NzeZWaVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Decoder Stack"
      ],
      "metadata": {
        "id": "zMgAb67dWgg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_layers, num_heads, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(num_heads, d_model, d_ff, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_output, src_mask, tgt_mask)\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "7I3XOM1rWjuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Load Dataset"
      ],
      "metadata": {
        "id": "L_b7lpC_FGgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets sentencepiece\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load OPUS Books English‚ÄìGerman dataset\n",
        "dataset = load_dataset(\"opus_books\", \"de-en\")\n",
        "train = dataset[\"train\"]\n",
        "\n",
        "# Correct slicing method\n",
        "subset = train.select(range(min(50000, len(train))))\n",
        "\n",
        "src_texts = [ex[\"de\"] for ex in subset[\"translation\"]]\n",
        "tgt_texts = [ex[\"en\"] for ex in subset[\"translation\"]]\n",
        "\n",
        "print(\"Loaded\", len(src_texts), \"sentence pairs\")\n",
        "print(\"Example:\\n\", src_texts[0], \"‚Üí\", tgt_texts[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "dacfc109e355408481c51a36a75e952b",
            "b04ed7312dfd445e9fc14098114c5c79",
            "28415cc4f6e54f0c89f2bb894fc1b422",
            "cbbabf858e734c82bbf777fe3e56c40a",
            "88abf30ba4ce4c5a855f3aac77bdebb7",
            "13427b0d93cd41d3834eca65db011cb7",
            "9c4419463dc2466691213803a995bceb",
            "fb07953282784d80a27469980f8abc26",
            "5ecdda746d604f958806b62479da56f3",
            "4ed934e2d9ff4239866004fa69c7d06d",
            "f7ee89b5e532493796da15902069d182",
            "c4786cc09aae4ef0ac39daae839f6300",
            "541bc243d51546d09c98b5ca85b3ca2e",
            "49c6d72faf774894afa9c6964918a32f",
            "8756f5361aae4d82916202ce985cceb9",
            "0178952a51574150bdda12d3b386d83f",
            "3ff978a944484d229de2a7dce6240a24",
            "ad07b3f53c3e4f1d869f2ccebed05983",
            "f45193be8a9547a68404097487c7987b",
            "4af71930e2964a6a8d714b8f85487e32",
            "4ecb84353d5d4d888e6bae91e05c93bb",
            "d18faf3a9bb74347861ab9d1b4bc4446",
            "587ad9e552954fcfa7815fcd4e92fba3",
            "2dc6ff4174d042339327cdadcb0957ab",
            "bc72fbff44b74c8cb40ca1a82b9adbcc",
            "3cf13e06f2cc4a67ab9155bd1a979d69",
            "abddb72904f845568d1774f8e7c8c1d3",
            "096525b9ef9849b7b78d3b5c9f750b91",
            "2d1b16c989e44807aaf75a14a750ba9c",
            "398d89c3aa094ff3940d55c948c59dbf",
            "2f83b3d49d014d57bb56e4b28df905fe",
            "4a9cfa32cc2b471098dc2e760a57e5f3",
            "879c37cd34194da782e41284cedd8872"
          ]
        },
        "id": "t4zf_BpVIVd-",
        "outputId": "10d959ef-c190-4649-eadc-35cf0b375278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dacfc109e355408481c51a36a75e952b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "de-en/train-00000-of-00001.parquet:   0%|          | 0.00/8.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4786cc09aae4ef0ac39daae839f6300"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/51467 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "587ad9e552954fcfa7815fcd4e92fba3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 50000 sentence pairs\n",
            "Example:\n",
            " Source: http://www.zeno.org - Contumax GmbH & Co. KG ‚Üí Source: Project Gutenberg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine both languages into a single text file for shared BPE\n",
        "with open(\"train_combined.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for de, en in zip(src_texts, tgt_texts):\n",
        "        f.write(de.strip() + \"\\n\")\n",
        "        f.write(en.strip() + \"\\n\")\n",
        "\n",
        "print(\"Combined text file created with\", len(src_texts) * 2, \"lines\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FzepnVZMJd2",
        "outputId": "0012b2cc-2f24-4f96-8fec-4a9cbfb2acc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined text file created with 100000 lines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train SentencePiece BPE Tokenizer (shared vocab)"
      ],
      "metadata": {
        "id": "TYVLzU42Hfi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "# Train SentencePiece tokenizer\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input=\"train_combined.txt\",\n",
        "    model_prefix=\"bpe\",\n",
        "    vocab_size=37000,         # same as paper\n",
        "    model_type=\"bpe\",         # Byte-Pair Encoding\n",
        "    character_coverage=1.0,   # cover all characters\n",
        "    pad_id=0, unk_id=1, bos_id=2, eos_id=3\n",
        ")\n",
        "\n",
        "print(\"‚úÖ SentencePiece tokenizer trained! Files generated: bpe.model, bpe.vocab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHhE04XLFFe-",
        "outputId": "802e0ec8-b355-4e3f-ad4f-38c9101d787e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ SentencePiece tokenizer trained! Files generated: bpe.model, bpe.vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Tokenizer & Test Encoding/Decoding"
      ],
      "metadata": {
        "id": "phqqxC6_QsMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp = spm.SentencePieceProcessor(model_file=\"bpe.model\")\n",
        "\n",
        "# Test on one pair\n",
        "src_example = src_texts[10]\n",
        "tgt_example = tgt_texts[10]\n",
        "\n",
        "src_ids = sp.encode(src_example, out_type=int)\n",
        "tgt_ids = sp.encode(tgt_example, out_type=int)\n",
        "\n",
        "print(\"German:\", src_example)\n",
        "print(\"‚Üí src_ids:\", src_ids[:20])\n",
        "print(\"English:\", tgt_example)\n",
        "print(\"‚Üí tgt_ids:\", tgt_ids[:20])\n",
        "\n",
        "# Decode back to verify\n",
        "print(\"Decoded back (src):\", sp.decode(src_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho4Iv1RAQrgR",
        "outputId": "d0e35de2-b8a1-4dea-a690-493def9d872d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "German: ¬ªJane, ich liebe weder Spitzfindigkeiten noch Fragen; au√üerdem ist es gradezu widerlich, wenn ein Kind √§ltere Leute in dieser Weise zur Rede stellt.\n",
            "‚Üí src_ids: [94, 5110, 36864, 147, 2815, 3031, 9272, 17226, 3561, 307, 4557, 36888, 6878, 217, 179, 22058, 357, 28596, 36864, 428]\n",
            "English: \"Jane, I don't like cavillers or questioners; besides, there is something truly forbidding in a child taking up her elders in that manner.\n",
            "‚Üí tgt_ids: [150, 5110, 36864, 63, 944, 36877, 36851, 547, 9366, 178, 229, 363, 1954, 229, 36888, 4381, 36864, 399, 128, 1041]\n",
            "Decoded back (src): ¬ªJane, ich liebe weder Spitzfindigkeiten noch Fragen; au√üerdem ist es gradezu widerlich, wenn ein Kind √§ltere Leute in dieser Weise zur Rede stellt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Tokenized Tensors"
      ],
      "metadata": {
        "id": "JOK3RCzlQ4U0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def prepare_example(src_text, tgt_text, sp):\n",
        "    src_ids = sp.encode(src_text, out_type=int)\n",
        "    tgt_ids = sp.encode(tgt_text, out_type=int)\n",
        "\n",
        "    src = [2] + src_ids + [3]         # <sos> + src + <eos>\n",
        "    tgt_in = [2] + tgt_ids            # <sos> + tgt\n",
        "    tgt_out = tgt_ids + [3]           # tgt + <eos>\n",
        "\n",
        "    return torch.tensor(src), torch.tensor(tgt_in), torch.tensor(tgt_out)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_in_batch, tgt_out_batch = zip(*batch)\n",
        "    src_batch = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
        "    tgt_in_batch = pad_sequence(tgt_in_batch, padding_value=0, batch_first=True)\n",
        "    tgt_out_batch = pad_sequence(tgt_out_batch, padding_value=0, batch_first=True)\n",
        "    return src_batch, tgt_in_batch, tgt_out_batch\n"
      ],
      "metadata": {
        "id": "Kjph_zoDQ39W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Small Dataset Loader"
      ],
      "metadata": {
        "id": "eE__-FJWRM6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Build a small subset for testing\n",
        "pairs = list(zip(src_texts[:1000], tgt_texts[:1000]))  # 1000 pairs for quick runs\n",
        "tokenized_data = [prepare_example(src, tgt, sp) for src, tgt in pairs]\n",
        "\n",
        "train_loader = DataLoader(tokenized_data, batch_size=32, collate_fn=collate_fn, shuffle=True)\n",
        "\n",
        "for src, tgt_in, tgt_out in train_loader:\n",
        "    print(\"Batch shapes ‚Üí src:\", src.shape, \"tgt_in:\", tgt_in.shape, \"tgt_out:\", tgt_out.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKa2fGXIQ0_W",
        "outputId": "5eaa9341-3ae5-4e90-9fa5-645723a53c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shapes ‚Üí src: torch.Size([32, 121]) tgt_in: torch.Size([32, 97]) tgt_out: torch.Size([32, 97])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6D5yKCmtFFHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Training loop"
      ],
      "metadata": {
        "id": "GhCOsV_Sjocw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQauUJWqf8HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jnU6VMdHjuqn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}